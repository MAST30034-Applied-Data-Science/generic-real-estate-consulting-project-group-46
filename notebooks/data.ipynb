{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d81ce0bf-c863-4922-b0cd-817b114742b4",
   "metadata": {},
   "source": [
    "# Scraping data\n",
    "\n",
    "Please scrape the property data from here. Part of the code is written by the University of Melbourne lecturer and tutor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5a5b74b-dae2-40f4-9a1d-f799cbcf6bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from json import dump\n",
    "from collections import defaultdict\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc69f94a-474a-4ee0-99c6-0340f6b3dce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "postcode = pd.read_csv('../data/raw/Australian-Postcode-Data-master/au_postcodes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50331856-302d-4829-ab0e-3e0f0daa1bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NSW    5124\n",
       "QLD    3456\n",
       "VIC    3260\n",
       "WA     1903\n",
       "SA     1783\n",
       "TAS     831\n",
       "NT      364\n",
       "ACT     154\n",
       "Name: state_code, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postcode['state_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef894cb8-7442-487a-b223-07675e660f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/831dtzvs55b0c08vg3m5yhf40000gn/T/ipykernel_56442/3654251172.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  code_vic = code_vic[postcode['accuracy'] == 4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "730"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_vic = postcode[postcode['state_code'] == 'VIC']\n",
    "code_vic = code_vic[postcode['accuracy'] == 4]\n",
    "code_vic = code_vic.drop_duplicates(subset=['postcode'])\n",
    "codes = code_vic['postcode'].tolist()\n",
    "len(codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bea63b-3926-4424-8879-3b4f68ad48f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b8fc09-32b9-4a49-8e1a-3e79be202645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "BASE_URL = \"https://www.domain.com.au\"\n",
    "N_PAGES = range(1,10) # update this to your liking\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (X11; CrOS x86_64 12871.102.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.141 Safari/537.36\"}\n",
    "# begin code\n",
    "property_metadata = defaultdict(dict)\n",
    "\n",
    "for code in codes: \n",
    "    url_links = []\n",
    "    print(code)\n",
    "    \n",
    "    # generate list of urls to visit\n",
    "    for page in N_PAGES:\n",
    "        url = BASE_URL + f\"/rent/?postcode={code}&page={page}\"\n",
    "        #print(url)\n",
    "        bs_object = BeautifulSoup(requests.get(url, headers=headers).text, \"html.parser\")\n",
    "\n",
    "            \n",
    "        # find the unordered list (ul) elements which are the results, then\n",
    "        # find all href (a) tags that are from the base_url website.\n",
    "        \n",
    "        if bs_object.find(\"ul\", {\"data-testid\": \"results\"}) is None:\n",
    "            break\n",
    "        \n",
    "        index_links = bs_object \\\n",
    "            .find(\n",
    "                \"ul\",\n",
    "                {\"data-testid\": \"results\"}\n",
    "            ) \\\n",
    "            .findAll(\n",
    "                \"a\",\n",
    "                href=re.compile(f\"{BASE_URL}/*\") # the `*` denotes wildcard any\n",
    "            )\n",
    "\n",
    "        for link in index_links:\n",
    "            # if its a property address, add it to the list\n",
    "            if 'address' in link['class']:\n",
    "                url_links.append(link['href'])\n",
    "    \n",
    "    # for each url, scrape some basic metadata\n",
    "    for property_url in url_links[1:]:\n",
    "        #print(property_url)\n",
    "        bs_object = BeautifulSoup(requests.get(property_url, headers=headers).text, \"html.parser\")\n",
    "\n",
    "        # looks for the header class to get property name\n",
    "        if bs_object.find(\"h1\", {\"class\": \"css-164r41r\"}) is not None:\n",
    "            property_metadata[property_url]['name'] = bs_object \\\n",
    "                .find(\"h1\", {\"class\": \"css-164r41r\"}) \\\n",
    "                .text\n",
    "        else:\n",
    "            property_metadata[property_url]['name'] = None\n",
    "            \n",
    "        # looks for rent cost\n",
    "        if bs_object.find(\"div\", {\"data-testid\": \"listing-details__summary-title\"}) is not None:\n",
    "            property_metadata[property_url]['cost_text'] = bs_object \\\n",
    "                .find(\"div\", {\"data-testid\": \"listing-details__summary-title\"}) \\\n",
    "                .text\n",
    "        else:\n",
    "            property_metadata[property_url]['cost_text'] = None\n",
    "        \n",
    "        # looks for property type\n",
    "        if bs_object.find(\"div\", {\"data-testid\": \"listing-summary-property-type\"}) is not None:\n",
    "            property_metadata[property_url]['type'] = bs_object \\\n",
    "                .find(\"div\", {\"data-testid\": \"listing-summary-property-type\"}) \\\n",
    "                .text\n",
    "        else:\n",
    "            property_metadata[property_url]['type'] = None\n",
    "            \n",
    "\n",
    "        # looks for nearest school title and distance\n",
    "        if bs_object.find(\"h5\", {\"data-testid\": \"fe-co-school-catchment-school-title\"}) is not None:\n",
    "            \n",
    "            property_metadata[property_url]['school_title'] = bs_object \\\n",
    "                .find(\"h5\", {\"data-testid\": \"fe-co-school-catchment-school-title\"}) \\\n",
    "                .text\n",
    "\n",
    "            property_metadata[property_url]['school_distance'] = bs_object \\\n",
    "                .find(\"div\", {\"data-testid\": \"fe-co-school-catchment-schoolDistance\"}) \\\n",
    "                .text\n",
    "\n",
    "        else:\n",
    "            property_metadata[property_url]['school_title'] = None\n",
    "            property_metadata[property_url]['school_distance'] = None\n",
    "            \n",
    "            \n",
    "        # looks for suburb info on domain\n",
    "        if  bs_object.find(\"div\", {\"data-testid\": \"suburb-insights__data-point-value\"}) is not None:\n",
    "        \n",
    "            property_metadata[property_url]['suburb_sold'] = bs_object \\\n",
    "                .findAll(\"div\", {\"data-testid\": \"suburb-insights__data-point-value\"})[2]\\\n",
    "                .text\n",
    "\n",
    "            property_metadata[property_url]['suburb_avg_day'] = bs_object \\\n",
    "                .findAll(\"div\", {\"data-testid\": \"suburb-insights__data-point-value\"})[3]\\\n",
    "                .text\n",
    "\n",
    "            property_metadata[property_url]['suburb_population'] = bs_object \\\n",
    "                .findAll(\"div\", {\"data-testid\": \"suburb-insights__data-point-value\"})[4]\\\n",
    "                .text\n",
    "\n",
    "            property_metadata[property_url]['suburb_age'] = bs_object \\\n",
    "                .findAll(\"div\", {\"data-testid\": \"suburb-insights__data-point-value\"})[5] \\\n",
    "                .text\n",
    "\n",
    "            property_metadata[property_url]['suburb_ower'] = bs_object \\\n",
    "                .findAll(\"span\", {\"data-testid\": \"left-value\"})[-2] \\\n",
    "                .text\n",
    "\n",
    "            property_metadata[property_url]['suburb_renter'] = bs_object \\\n",
    "                .findAll(\"span\", {\"data-testid\": \"right-value\"})[-2] \\\n",
    "                .text\n",
    "        \n",
    "            property_metadata[property_url]['suburb_family'] = bs_object \\\n",
    "                .findAll(\"span\", {\"data-testid\": \"left-value\"})[-1] \\\n",
    "                .text\n",
    "\n",
    "            property_metadata[property_url]['suburb_single'] = bs_object \\\n",
    "                .findAll(\"span\", {\"data-testid\": \"right-value\"})[-1] \\\n",
    "                .text\n",
    "        else:\n",
    "            property_metadata[property_url]['suburb_sold'] = None\n",
    "            property_metadata[property_url]['suburb_avg_day'] = None\n",
    "            property_metadata[property_url]['suburb_population'] = None\n",
    "            property_metadata[property_url]['suburb_age'] = None\n",
    "            property_metadata[property_url]['suburb_ower'] = None\n",
    "            property_metadata[property_url]['suburb_renter'] = None\n",
    "            property_metadata[property_url]['suburb_family'] = None\n",
    "            property_metadata[property_url]['suburb_single'] = None\n",
    "            \n",
    "        # extract coordinates from the hyperlink provided\n",
    "        # i'll let you figure out what this does :P\n",
    "        property_metadata[property_url]['coordinates'] = [\n",
    "            float(coord) for coord in re.findall(\n",
    "                r'destination=([-\\s,\\d\\.]+)',\n",
    "                bs_object \\\n",
    "                    .find(\n",
    "                        \"a\",\n",
    "                        {\"target\": \"_blank\", 'rel': \"noopener noreferer\"}\n",
    "                    ) \\\n",
    "                    .attrs['href']\n",
    "            )[0].split(',')\n",
    "        ]\n",
    "\n",
    "        property_metadata[property_url]['rooms'] = [\n",
    "            re.findall(r'\\d\\s[A-Za-z]+', feature.text) for feature in bs_object \\\n",
    "                .find(\"div\", {\"data-testid\": \"property-features\"}) \\\n",
    "                .findAll(\"span\", {\"data-testid\": \"property-features-text-container\"})\n",
    "        ]\n",
    "\n",
    "        property_metadata[property_url]['desc'] = re \\\n",
    "            .sub(r'<br\\/>', '\\n', str(bs_object.find(\"p\"))) \\\n",
    "            .strip('</p>')\n",
    "        \n",
    "        property_metadata[property_url]['postcode'] = code\n",
    "\n",
    "with open('../data/curated/domain.json', 'w') as f:\n",
    "    dump(property_metadata, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36e6a05-883a-42fd-aa9c-a78ce2a67cd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
